# -*- coding: utf-8 -*-
"""GermanCredit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JN1omO3-XMK8ipnxrrWVl-zyWMS6X4hV

#Finance: German-Credit for assessing credit risk
The data cleaning code and conventional implementation was written building on the following project by Janio Martinez Bachmann.
https://www.kaggle.com/janiobachmann/german-credit-analysis-a-risk-perspective
However, I have reworked and adapted it to make it suitable for this project.

#Import Libraries
"""

import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib.pyplot as plt
sns.set(rc={'figure.figsize':(11.7,8.27)})

"""#Load Dataset"""

df = pd.read_csv('german_credit_data.csv')
df = df.iloc[:, 1:]
print(df.head())

"""#Task 2 : Data Analysis

Fill the missing values. For checking account, fill with none. Then drop any rows with null values.
"""

df['Checking account'] = df['Checking account'].fillna('None')
df.dropna(inplace=True)

"""Binning age into age groups. These are in 10 year groups between 30 and 70. Then there are also groups for those under 30 and those over 70."""

for col in [df]:
    col.loc[(col['Age'] > 18) & (col['Age'] <= 29), 'Age_Group'] = 'Under 30'
    col.loc[(col['Age'] > 29) & (col['Age'] <= 40), 'Age_Group'] = '30-40'
    col.loc[(col['Age'] > 40) & (col['Age'] <= 50), 'Age_Group'] = '40-50'
    col.loc[(col['Age'] > 50)& (col['Age'] <= 60), 'Age_Group'] = '50-60'
    col.loc[col['Age'] > 60, 'Age_Group'] = 'Over 60'
df=df.sort_values(by=['Age'])

"""Look at the number of people in each age group. We can see that there are more younger applicants than older ones. For females, the highest number of applicats were under 30, for males, they are aged between 30 and 40."""

g = sns.countplot(
    x=df['Age_Group'],hue=df['Sex']
)

"""The graph below shows the number of people of each sex in the dataset. We can see that there are double the amount of males than females."""

g = sns.countplot(
    x=df['Sex']
)

"""Plotting a bar graph of age group and risk (raw numbers).



"""

g = sns.countplot(
    x=df['Age_Group'], hue=df['Risk']
)

"""Risk vs Age Group (proportion)"""

x, y, hue = "Age_Group", "proportion", "Risk"


(df[x]
 .groupby(df[hue])
 .value_counts(normalize=True)
 .rename(y)
 .reset_index()
 .pipe((sns.barplot, "data"), x=x, y=y, hue=hue))

"""Risk vs Sex"""

x, y, hue = "Risk", "proportion", "Sex"


(df[x]
 .groupby(df[hue])
 .value_counts(normalize=True)
 .rename(y)
 .reset_index()
 .pipe((sns.barplot, "data"), x=x, y=y, hue=hue))

"""For each sex, we can see the proportion of people applying for loans for each purpose. Females were more likely to apply for a credit loan to buy furniture and equipment then males, whereas males were much more likely to apply for loans to invest in business."""

x, y, hue = "Purpose", "proportion", "Sex"
hue_order = ["Male", "Female"]

(df[x]
 .groupby(df[hue])
 .value_counts(normalize=True)
 .rename(y)
 .reset_index()
 .pipe((sns.barplot, "data"), x=x, y=y, hue=hue))

print(df.describe())

df['Age_Group'].value_counts()[:3].index.tolist()

"""# Task 3: Conventional Implementation

Import relevant modules and perform one hot encoding for X.
"""

from sklearn.preprocessing import OneHotEncoder

X=df[['Age_Group','Sex','Job','Housing','Saving accounts','Checking account','Credit amount','Duration','Purpose']]
y=df[['Risk']]

enc = OneHotEncoder(handle_unknown='ignore')
enc.fit(X)
X_enc=enc.transform(X).toarray()
print(X_enc)

"""Split into test and training sets"""

X_train, X_test, y_train, y_test = train_test_split(X_enc, y, test_size=0.3, random_state=42)

"""Look at the number of cases of good and bad risk in the original dataset. From this we can see that 67.2% of the applicants were categorised as being of good risk and 32.% of bad risk."""

print(df["Risk"].value_counts())

"""We need to ensure that there is a similar ratio of good to bad risk applicants in both the training and testing sets. In the training set, there is 66.9% good risk and 33.1% bad. In the test set, the percentages are 67.9% and 32.1% respectively. Therefore, we have similar ratios to the original data set."""

print(y_train["Risk"].value_counts())
print(y_test["Risk"].value_counts())

"""Build the model"""

from sklearn import svm
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

"""Implement gridsearchcv to see which are the optimum parameters"""

params = {'C': [0.75, 0.85, 0.95, 1], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2,3, 4, 5]}

svc_clf = svm.SVC(random_state=42)

grid_search_cv = GridSearchCV(svc_clf, params)
grid_search_cv.fit(X_train, y_train)

print(grid_search_cv.best_params_)

"""Use the parameters found in the previous step to produce a model and check the accuracy. With these parameters we get an accuracy score of 0.7439."""

clf = svm.SVC(kernel='poly', C = 1.0, degree=2)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
print(accuracy_score(y_test, y_pred))